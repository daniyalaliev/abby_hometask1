# Обработка корпуса статей

## Используемые средства:

### Датасет

В качестве корпуса статей для обработки я взял около 1000 рандомных статей на хабре, для скачивания которых были применены стандартно библиотеки requests и BeautifulSoup.

### Stanza

Для токенизации, определения частей речи, определения зависимостей и их типов используем стэнфордскую библиотеку - stanza. Эта библиотека поддерживает работу более чем с 70 различными языками и построена с использованием высокоточных компонентов нейронной сети.

> stanza.Pipeline('ru', processors='tokenize,pos,lemma,depparse')

### MyStem

Я не нашел как в stanza выполняется лемматизация (хотя она там наверняка есть), так переложил отвественность за нее на отечественный продукт - библиотека Mystem от Яндекса.

## Омонимы

## Средства

## Эллипсисы
> lkefs
